python -m experiments.training.train_sentence_transformer --model_name nomic-ai/modernbert-embed-base --batch_size 64
python -m experiments.training.train_paragraph_sentence_transformer --model_name nlpaueb/legal-bert-base-uncased --batch_size 8 --epochs 3
python -m eval.paragraph_evaluation --model_path models/legal-bert-ft --model_name legal_bert_ft

python -m util.anonymise_parallel


python3 -m experiments.training.single_paragraph_transformer --model_name=google-bert/bert-base-uncased \
--training_file_path=data/data_splits/training/ --training_file=anchor_positive_W3.tsv \
--eval_file_path=data/data_splits/training/ --eval_file=eval_positive_negative_W3.tsv \
--run_alias=positive_negative_W3 --batch_size=2 --eval_batch_size=2

python3 -m experiments.training.single_paragraph_transformer --model_name=google-bert/bert-base-uncased \
--training_file_path=data/data_splits/training/ --training_file=anchor_positive_W1.tsv \
--eval_file_path=data/data_splits/training/ --eval_file=eval_positive_negative_W1.tsv \
--run_alias=positive_negative_W1 --batch_size=2 --eval_batch_size=2

python -m experiments.evaluation.single_para_eval --model_name models/nlpaueb_legal-bert-base-uncased_positive_negative_W1/final/ --candidates_file_path data/data_splits/ --gold_file_path data/data_splits/ --candidates_file candidates_1P.tsv --gold_file gold_1P.tsv --run_alias 1P eval


